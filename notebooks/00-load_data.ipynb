{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb9dbc0b-a2f0-4c93-9c34-01ac808c9e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run init_notebook.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2878161c-5171-4e05-9a94-8cfbd7078a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import eurostat\n",
    "from src.utils import load_pd_df, get_dt_index, save_pd_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29db529a-2a88-472a-b573-e9b5b1209d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# interest rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6b06e1f-41c7-44c2-8707-22d39dbb5edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(DATA_DIR, 'ecb_interest_rates.csv'), low_memory=False)\n",
    "df = df[df['REF_AREA'] == 'DE'].dropna(axis=1)\n",
    "df['date'] = df['TIME_PERIOD'].apply(lambda x: datetime.strptime(x, \"%Y-%m\"))\n",
    "df = df[df['TITLE'] == list(set(df['TITLE']))[1]]\n",
    "df.set_index('date', inplace=True)\n",
    "\n",
    "mir = df[['OBS_VALUE']].rename(columns={'OBS_VALUE': 'mir'}) / 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5822740a-2680-4fe1-8a9b-feefb8347666",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pd_df(mir, 'mir.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c458c583-2f16-4709-b397-3a6005c1daa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eurostat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be8a524b-e069-43df-a7b3-1d2413cd4b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "codes = eurostat.get_toc_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c9fd803-8afe-4366-af9b-b949c15a7842",
   "metadata": {},
   "outputs": [],
   "source": [
    "[i for i in codes['title'] if 'consum'.lower() in i.lower()];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5349e51c-afef-420d-8f5d-0ee6dc237fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "filt = [\n",
    "    'HICP - energy', \n",
    "    'HICP - food, alcohol and tobacco',\n",
    "    'Gross domestic product (GDP) at current market prices by metropolitan regions',\n",
    "    'Gross domestic product (GDP) at market prices - quarterly data',\n",
    "    'HICP - inflation rate',\n",
    "    'HICP - all items excluding energy and seasonal food',\n",
    "    'HICP - energy',\n",
    "    'HICP - monthly data (index)',\n",
    "    'Final consumption expenditure',\n",
    "]\n",
    "filt = [i in filt for i in codes['title']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32dfdab0-a836-4512-b262-155c7b1fcac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "codes[filt];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91304b8f-f1e5-4b75-91d6-8b951573830c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# overall inflation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5331d14-541e-4842-ab44-47dd3226c4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = eurostat.get_data('med_ec2') #, filter_pars={'geo': ['DE','FR']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db426671-6f62-437e-a2b4-5f946ff21bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data[1:], columns=data[0]).transpose()\n",
    "df = df.loc[:, (df.loc['unit'] == 'I05') & (df.loc['coicop'] == 'CP00')]\n",
    "df.columns = [f'cpi_{i}' for i in df.loc['geo\\TIME_PERIOD'].values]\n",
    "\n",
    "cpi = df.iloc[5:].copy().dropna().astype(float)\n",
    "cpi.index = [datetime(int(i[:4]), int(i[5:7]), 1) for i in cpi.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57956631-b3e9-473a-b393-0052b9f792c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cpi['pi_de'] = np.log(cpi['cpi_DE']).diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "84996f23-57bf-438d-9dfa-2c175615bf50",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pd_df(cpi, 'cpi.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f7cb87c5-5d80-42a6-9f8c-58a53005abb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# food tobaco inflation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "58cc1198-4f5b-42ba-981c-810a0d71f271",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = eurostat.get_data('TEICP260', filter_pars={'geo': ['DE']})\n",
    "data = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "53a72797-ba65-4cf2-90e8-5b72d222488f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>freq</th>\n",
       "      <th>coicop</th>\n",
       "      <th>unit</th>\n",
       "      <th>geo\\TIME_PERIOD</th>\n",
       "      <th>2023-02</th>\n",
       "      <th>2023-03</th>\n",
       "      <th>2023-04</th>\n",
       "      <th>2023-05</th>\n",
       "      <th>2023-06</th>\n",
       "      <th>2023-07</th>\n",
       "      <th>2023-08</th>\n",
       "      <th>2023-09</th>\n",
       "      <th>2023-10</th>\n",
       "      <th>2023-11</th>\n",
       "      <th>2023-12</th>\n",
       "      <th>2024-01</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>FOOD</td>\n",
       "      <td>I15</td>\n",
       "      <td>DE</td>\n",
       "      <td>139.5</td>\n",
       "      <td>141.3</td>\n",
       "      <td>141.1</td>\n",
       "      <td>141.1</td>\n",
       "      <td>141.2</td>\n",
       "      <td>141.2</td>\n",
       "      <td>141.0</td>\n",
       "      <td>141.5</td>\n",
       "      <td>141.6</td>\n",
       "      <td>142.4</td>\n",
       "      <td>142.4</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>FOOD</td>\n",
       "      <td>PCH_M1</td>\n",
       "      <td>DE</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>FOOD</td>\n",
       "      <td>PCH_M12</td>\n",
       "      <td>DE</td>\n",
       "      <td>18.0</td>\n",
       "      <td>18.6</td>\n",
       "      <td>15.5</td>\n",
       "      <td>13.6</td>\n",
       "      <td>12.6</td>\n",
       "      <td>10.7</td>\n",
       "      <td>9.2</td>\n",
       "      <td>8.1</td>\n",
       "      <td>7.1</td>\n",
       "      <td>6.6</td>\n",
       "      <td>5.8</td>\n",
       "      <td>5.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  freq coicop     unit geo\\TIME_PERIOD 2023-02 2023-03 2023-04 2023-05  \\\n",
       "0    M   FOOD      I15              DE   139.5   141.3   141.1   141.1   \n",
       "1    M   FOOD   PCH_M1              DE     2.0     1.3    -0.1     0.0   \n",
       "2    M   FOOD  PCH_M12              DE    18.0    18.6    15.5    13.6   \n",
       "\n",
       "  2023-06 2023-07 2023-08 2023-09 2023-10 2023-11 2023-12 2024-01  \n",
       "0   141.2   141.2   141.0   141.5   141.6   142.4   142.4    None  \n",
       "1     0.1     0.0    -0.1     0.4     0.1     0.6     0.0     0.9  \n",
       "2    12.6    10.7     9.2     8.1     7.1     6.6     5.8     5.1  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data=data[1:], columns=data[0])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d929bc8f-7406-4d87-85b4-b8b1f9045670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pi prognosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "747a9ca9-8dfd-41f8-b501-30de328b63fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_dt_index(load_pd_df('ecb_prognosis_hicp_dec_2021.csv'), dt_index_col=\"DATE\").iloc[:, 1:]\n",
    "df.index.name = 'date'\n",
    "df.columns = [\"infl_forecast\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53069781-f55d-49a3-8ce5-cda62c4ef9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = load_pd_df('ecb_prognosis_hicp_jun_2021.csv')\n",
    "df1['date'] = df1.DATE.apply(lambda x: datetime(int(x[:4]), 6, 30))\n",
    "df1 = df1.drop('DATE', axis=1).set_index('date').iloc[:, 1:]\n",
    "df1.columns = [\"infl_forecast\"]\n",
    "\n",
    "df = pd.concat([df, df1], axis=0).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "58afe557-0b48-40ec-854a-7b43fd8a19b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pd_df(df, 'infl_prognonsis.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6eeb1f-fc81-4f63-bce2-5b8826b3f61e",
   "metadata": {},
   "source": [
    "# hhp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ac1e1c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bophh_suf_202304_v01_wave01.dta\n",
      "bophh_suf_202304_v01_wave02.dta\n",
      "bophh_suf_202304_v01_wave03.dta\n",
      "bophh_suf_202304_v01_wave04.dta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LukasGrahl\\AppData\\Local\\Temp\\ipykernel_23700\\1408175798.py:5: UnicodeWarning: \n",
      "One or more strings in the dta file could not be decoded using utf-8, and\n",
      "so the fallback encoding of latin-1 is being used.  This can happen when a file\n",
      "has been incorrectly encoded by Stata or some other software. You should verify\n",
      "the string values returned are correct.\n",
      "  dta = pd.read_stata(os.path.join(DATA_DIR, 'hhs', file))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bophh_suf_202304_v01_wave05.dta\n",
      "bophh_suf_202304_v01_wave06.dta\n",
      "bophh_suf_202304_v01_wave07.dta\n",
      "bophh_suf_202304_v01_wave08.dta\n",
      "bophh_suf_202304_v01_wave09.dta\n",
      "bophh_suf_202304_v01_wave10.dta\n",
      "bophh_suf_202304_v01_wave11.dta\n",
      "bophh_suf_202304_v01_wave12.dta\n",
      "bophh_suf_202304_v01_wave13.dta\n",
      "bophh_suf_202304_v01_wave14.dta\n",
      "bophh_suf_202304_v01_wave15.dta\n",
      "bophh_suf_202304_v01_wave16.dta\n",
      "bophh_suf_202304_v01_wave17.dta\n",
      "bophh_suf_202304_v01_wave18.dta\n",
      "bophh_suf_202304_v01_wave19.dta\n",
      "bophh_suf_202304_v01_wave20.dta\n",
      "bophh_suf_202304_v01_wave21.dta\n",
      "bophh_suf_202304_v01_wave22.dta\n",
      "bophh_suf_202304_v01_wave23.dta\n",
      "bophh_suf_202304_v01_wave24.dta\n",
      "bophh_suf_202304_v01_wave25.dta\n",
      "bophh_suf_202304_v01_wave26.dta\n",
      "bophh_suf_202304_v01_wave27.dta\n",
      "'utf-8' codec can't decode byte 0xfc in position 8: invalid start byte\n",
      "bophh_suf_202304_v01_wave28.dta\n",
      "'utf-8' codec can't decode byte 0x80 in position 5: invalid start byte\n",
      "bophh_suf_202304_v01_wave29.dta\n",
      "bophh_suf_202304_v01_wave30.dta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LukasGrahl\\AppData\\Local\\Temp\\ipykernel_23700\\1408175798.py:5: UnicodeWarning: \n",
      "One or more strings in the dta file could not be decoded using utf-8, and\n",
      "so the fallback encoding of latin-1 is being used.  This can happen when a file\n",
      "has been incorrectly encoded by Stata or some other software. You should verify\n",
      "the string values returned are correct.\n",
      "  dta = pd.read_stata(os.path.join(DATA_DIR, 'hhs', file))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bophh_suf_202304_v01_wave31.dta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LukasGrahl\\AppData\\Local\\Temp\\ipykernel_23700\\1408175798.py:5: UnicodeWarning: \n",
      "One or more strings in the dta file could not be decoded using utf-8, and\n",
      "so the fallback encoding of latin-1 is being used.  This can happen when a file\n",
      "has been incorrectly encoded by Stata or some other software. You should verify\n",
      "the string values returned are correct.\n",
      "  dta = pd.read_stata(os.path.join(DATA_DIR, 'hhs', file))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bophh_suf_202304_v01_wave32.dta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LukasGrahl\\AppData\\Local\\Temp\\ipykernel_23700\\1408175798.py:5: UnicodeWarning: \n",
      "One or more strings in the dta file could not be decoded using utf-8, and\n",
      "so the fallback encoding of latin-1 is being used.  This can happen when a file\n",
      "has been incorrectly encoded by Stata or some other software. You should verify\n",
      "the string values returned are correct.\n",
      "  dta = pd.read_stata(os.path.join(DATA_DIR, 'hhs', file))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bophh_suf_202304_v01_wave33.dta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LukasGrahl\\AppData\\Local\\Temp\\ipykernel_23700\\1408175798.py:5: UnicodeWarning: \n",
      "One or more strings in the dta file could not be decoded using utf-8, and\n",
      "so the fallback encoding of latin-1 is being used.  This can happen when a file\n",
      "has been incorrectly encoded by Stata or some other software. You should verify\n",
      "the string values returned are correct.\n",
      "  dta = pd.read_stata(os.path.join(DATA_DIR, 'hhs', file))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bophh_suf_202304_v01_wave34.dta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LukasGrahl\\AppData\\Local\\Temp\\ipykernel_23700\\1408175798.py:5: UnicodeWarning: \n",
      "One or more strings in the dta file could not be decoded using utf-8, and\n",
      "so the fallback encoding of latin-1 is being used.  This can happen when a file\n",
      "has been incorrectly encoded by Stata or some other software. You should verify\n",
      "the string values returned are correct.\n",
      "  dta = pd.read_stata(os.path.join(DATA_DIR, 'hhs', file))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bophh_suf_202304_v01_wave35.dta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LukasGrahl\\AppData\\Local\\Temp\\ipykernel_23700\\1408175798.py:5: UnicodeWarning: \n",
      "One or more strings in the dta file could not be decoded using utf-8, and\n",
      "so the fallback encoding of latin-1 is being used.  This can happen when a file\n",
      "has been incorrectly encoded by Stata or some other software. You should verify\n",
      "the string values returned are correct.\n",
      "  dta = pd.read_stata(os.path.join(DATA_DIR, 'hhs', file))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bophh_suf_202304_v01_wave36.dta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LukasGrahl\\AppData\\Local\\Temp\\ipykernel_23700\\1408175798.py:5: UnicodeWarning: \n",
      "One or more strings in the dta file could not be decoded using utf-8, and\n",
      "so the fallback encoding of latin-1 is being used.  This can happen when a file\n",
      "has been incorrectly encoded by Stata or some other software. You should verify\n",
      "the string values returned are correct.\n",
      "  dta = pd.read_stata(os.path.join(DATA_DIR, 'hhs', file))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bophh_suf_202304_v01_wave37.dta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LukasGrahl\\AppData\\Local\\Temp\\ipykernel_23700\\1408175798.py:5: UnicodeWarning: \n",
      "One or more strings in the dta file could not be decoded using utf-8, and\n",
      "so the fallback encoding of latin-1 is being used.  This can happen when a file\n",
      "has been incorrectly encoded by Stata or some other software. You should verify\n",
      "the string values returned are correct.\n",
      "  dta = pd.read_stata(os.path.join(DATA_DIR, 'hhs', file))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bophh_suf_202304_v01_wave38.dta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LukasGrahl\\AppData\\Local\\Temp\\ipykernel_23700\\1408175798.py:5: UnicodeWarning: \n",
      "One or more strings in the dta file could not be decoded using utf-8, and\n",
      "so the fallback encoding of latin-1 is being used.  This can happen when a file\n",
      "has been incorrectly encoded by Stata or some other software. You should verify\n",
      "the string values returned are correct.\n",
      "  dta = pd.read_stata(os.path.join(DATA_DIR, 'hhs', file))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bophh_suf_202304_v01_wave39.dta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LukasGrahl\\AppData\\Local\\Temp\\ipykernel_23700\\1408175798.py:5: UnicodeWarning: \n",
      "One or more strings in the dta file could not be decoded using utf-8, and\n",
      "so the fallback encoding of latin-1 is being used.  This can happen when a file\n",
      "has been incorrectly encoded by Stata or some other software. You should verify\n",
      "the string values returned are correct.\n",
      "  dta = pd.read_stata(os.path.join(DATA_DIR, 'hhs', file))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bophh_suf_202304_v01_wave40.dta\n",
      "bophh_suf_202304_v01_wave41.dta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LukasGrahl\\AppData\\Local\\Temp\\ipykernel_23700\\1408175798.py:5: UnicodeWarning: \n",
      "One or more strings in the dta file could not be decoded using utf-8, and\n",
      "so the fallback encoding of latin-1 is being used.  This can happen when a file\n",
      "has been incorrectly encoded by Stata or some other software. You should verify\n",
      "the string values returned are correct.\n",
      "  dta = pd.read_stata(os.path.join(DATA_DIR, 'hhs', file))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bophh_suf_202304_v01_wave42.dta\n",
      "bophh_suf_202304_v01_wave43.dta\n",
      "bophh_suf_202304_v01_wave44.dta\n",
      "bophh_suf_202304_v01_wave45.dta\n"
     ]
    }
   ],
   "source": [
    "dfs, metadata = [], []\n",
    "for file in os.listdir(os.path.join(DATA_DIR, 'hhs')):\n",
    "    print(file)\n",
    "    try:\n",
    "        dta = pd.read_stata(os.path.join(DATA_DIR, 'hhs', file))\n",
    "        dfs.append(dta)\n",
    "        metadata.append(metadata)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a8de37c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat(dfs, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "cf357a0c-744e-47c3-91d7-6d3e2458bcf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['riskaversion'] = data.riskaversion.cat.codes.replace({-1:np.nan})\n",
    "data['ambig_lot'] = data.ambig_lot.cat.codes.replace({-1:np.nan})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "efbc15ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_cols_parse = {\n",
    "    'id': float,\n",
    "#     'date': 'datetime64[ns]',\n",
    "    'year': int,\n",
    "    'month': int,\n",
    "    'day': int,\n",
    "    'riskaversion': str,\n",
    "    'expint_sav': float,\n",
    "    'devinfpoint\n",
    "    ': float,\n",
    "    'inflexppoint': float    \n",
    "}\n",
    "dict_cols_parse.update({f'infexprob_{i}': str for i in list(map(chr, range(97, 107)))})\n",
    "dict_cols_parse.update({f'incexp_{i}': str for i in list(map(chr, range(97, 107)))})\n",
    "\n",
    "_ = [\n",
    "        \"don't know\",\n",
    "        'no answer',\n",
    "        'does not apply',\n",
    "    ]\n",
    "dict_parse_nan = dict(zip(_, list([np.nan]) * len(_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "01f21c59-406d-4114-8214-7c9bf65a8c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data[list(dict_cols_parse.keys())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a5d9d204",
   "metadata": {},
   "outputs": [],
   "source": [
    "del data, dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7c1cb7bb-474c-4b0c-a5f9-14aab073d878",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LukasGrahl\\AppData\\Local\\Temp\\ipykernel_23700\\3676133331.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['date'] = df[['year', 'month', 'day']].apply(lambda x: datetime(*x.astype(int)), axis=1).rename('date').values\n"
     ]
    }
   ],
   "source": [
    "df['date'] = df[['year', 'month', 'day']].apply(lambda x: datetime(*x.astype(int)), axis=1).rename('date').values\n",
    "df = df.drop(['year', 'month', 'day'], axis=1)\n",
    "df['inflexppoint'] = df['inflexppoint'].apply(lambda x: dict_parse_nan[x] if x in dict_parse_nan.keys() else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2e5a2a55-9ae8-4adc-b2c8-c60d70717a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['devinfpoint'] = df['devinfpoint'].apply(lambda x: dict_parse_nan[x] if x in dict_parse_nan.keys() else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0ae88a6d-166c-4bdc-81ec-7c4be775168d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LukasGrahl\\AppData\\Local\\Temp\\ipykernel_23700\\2627956439.py:1: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.replace(dict_parse_nan)\n"
     ]
    }
   ],
   "source": [
    "df = df.replace(dict_parse_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d978458b-bcbd-4b19-a3c4-f29428412581",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.astype({k: v for k, v in dict_cols_parse.items() if k in df.columns})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "00f85c29-ce8d-44fa-ae91-c6cb558f36bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[df.inflexppoint.dropna().index]\n",
    "df.sort_values('date', inplace=True)\n",
    "\n",
    "df['y_m'] = df.date.dt.to_period('M').astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "bdfb2554-cd3c-4fc3-91b5-a1958eb256e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.replace({'nan': np.nan})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d1904bec-5e0a-493a-8c5a-56ebff97ba2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date_forecast'] = df.date.apply(lambda x: datetime(x.year + 1, x.month, x.day))\n",
    "df = df.rename(columns={'date': 'date_recorded'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "65a51545-9790-4969-9b69-46aabfee7377",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'riskaversion', 'expint_sav', 'devinfpoint', 'inflexppoint',\n",
       "       'infexprob_a', 'infexprob_b', 'infexprob_c', 'infexprob_d',\n",
       "       'infexprob_e', 'infexprob_f', 'infexprob_g', 'infexprob_h',\n",
       "       'infexprob_i', 'infexprob_j', 'incexp_a', 'incexp_b', 'incexp_c',\n",
       "       'incexp_d', 'incexp_e', 'incexp_f', 'incexp_g', 'incexp_h', 'incexp_i',\n",
       "       'incexp_j', 'date_recorded', 'y_m', 'date_forecast'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "43d19764-4a39-4927-ac9b-c3463058807c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_feather(os.path.join(DATA_DIR, 'hhp.feather'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ee3c04-1c77-4a1a-b9d6-7355ba0f9b7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mamba_env_memoire2",
   "language": "python",
   "name": "mamba_env_memoire2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
