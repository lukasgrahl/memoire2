{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb9dbc0b-a2f0-4c93-9c34-01ac808c9e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run init_notebook.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2878161c-5171-4e05-9a94-8cfbd7078a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import eurostat\n",
    "from src.utils import load_pd_df, get_dt_index, save_pd_df\n",
    "from pandas_datareader.fred import FredReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29db529a-2a88-472a-b573-e9b5b1209d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# interest rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55a638d7-f414-42a7-873e-bb474bdfcfc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "depo = FredReader('ECBDFR', start=datetime(2019,1,1), end=datetime.today()).read()\n",
    "depo = depo.rename(columns={'ECBDFR': 'ecb_rate'}) / 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e6b06e1f-41c7-44c2-8707-22d39dbb5edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(DATA_DIR, 'ecb_interest_rates.csv'), low_memory=False)\n",
    "df = df[df['REF_AREA'] == 'DE'].dropna(axis=1)\n",
    "df['date'] = df['TIME_PERIOD'].apply(lambda x: datetime.strptime(x, \"%Y-%m\"))\n",
    "df = df[df['TITLE'] == list(set(df['TITLE']))[1]]\n",
    "df.set_index('date', inplace=True)\n",
    "\n",
    "mir = df[['OBS_VALUE']].rename(columns={'OBS_VALUE': 'mir'}) / 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52eb4713-6174-4b98-967e-f4fe82986362",
   "metadata": {},
   "outputs": [],
   "source": [
    "mir = mir.join(depo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "322a82e7-6cc5-446e-b24b-4ad119fbead4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mir = mir.ffill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5822740a-2680-4fe1-8a9b-feefb8347666",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pd_df(mir, 'mir.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c458c583-2f16-4709-b397-3a6005c1daa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eurostat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be8a524b-e069-43df-a7b3-1d2413cd4b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "codes = eurostat.get_toc_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c9fd803-8afe-4366-af9b-b949c15a7842",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Loan and deposit one year interest rate']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in codes['title'] if 'deposit'.lower() in i.lower()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d7aaed-e185-4bf3-8d5e-35846c72fc36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5349e51c-afef-420d-8f5d-0ee6dc237fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "filt = [\n",
    "    'HICP - energy', \n",
    "    'HICP - food, alcohol and tobacco',\n",
    "    'Gross domestic product (GDP) at current market prices by metropolitan regions',\n",
    "    'Gross domestic product (GDP) at market prices - quarterly data',\n",
    "    'HICP - inflation rate',\n",
    "    'HICP - all items excluding energy and seasonal food',\n",
    "    'HICP - energy',\n",
    "    'HICP - monthly data (index)',\n",
    "    'Final consumption expenditure',\n",
    "    'Unemployment rate',\n",
    "    'Unemployment rate by education level',\n",
    "    'Unemployment rate (%) - monthly data',\n",
    "    'Loan and deposit one year interest rate',\n",
    "]\n",
    "filt = [i in filt for i in codes['title']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "32dfdab0-a836-4512-b262-155c7b1fcac7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>code</th>\n",
       "      <th>type</th>\n",
       "      <th>last update of data</th>\n",
       "      <th>last table structure change</th>\n",
       "      <th>data start</th>\n",
       "      <th>data end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>Final consumption expenditure</td>\n",
       "      <td>MED_EC2</td>\n",
       "      <td>dataset</td>\n",
       "      <td>2020-05-28T23:00:00+0200</td>\n",
       "      <td>2020-05-28T23:00:00+0200</td>\n",
       "      <td>2005</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>Unemployment rate</td>\n",
       "      <td>MED_PS421</td>\n",
       "      <td>dataset</td>\n",
       "      <td>2020-05-28T23:00:00+0200</td>\n",
       "      <td>2020-05-28T23:00:00+0200</td>\n",
       "      <td>2005</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>Unemployment rate by education level</td>\n",
       "      <td>MED_PS422</td>\n",
       "      <td>dataset</td>\n",
       "      <td>2016-08-29T23:00:00+0200</td>\n",
       "      <td>2023-12-21T23:00:00+0100</td>\n",
       "      <td>2000</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>Gross domestic product (GDP) at current market...</td>\n",
       "      <td>MET_10R_3GDP</td>\n",
       "      <td>dataset</td>\n",
       "      <td>2024-02-28T23:00:00+0100</td>\n",
       "      <td>2024-02-28T23:00:00+0100</td>\n",
       "      <td>2000</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1327</th>\n",
       "      <td>HICP - monthly data (index)</td>\n",
       "      <td>PRC_HICP_MIDX</td>\n",
       "      <td>dataset</td>\n",
       "      <td>2024-03-01T11:00:00+0100</td>\n",
       "      <td>2024-03-01T11:00:00+0100</td>\n",
       "      <td>1996-01</td>\n",
       "      <td>2024-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1330</th>\n",
       "      <td>HICP - monthly data (index)</td>\n",
       "      <td>PRC_HICP_MIDX$DV_1082</td>\n",
       "      <td>dataset</td>\n",
       "      <td>2024-03-01T11:00:00+0100</td>\n",
       "      <td>2024-03-01T11:00:00+0100</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1333</th>\n",
       "      <td>HICP - monthly data (index)</td>\n",
       "      <td>PRC_HICP_MIDX$DV_651</td>\n",
       "      <td>dataset</td>\n",
       "      <td>2024-03-01T11:00:00+0100</td>\n",
       "      <td>2024-03-01T11:00:00+0100</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2148</th>\n",
       "      <td>Unemployment rate (%) - monthly data</td>\n",
       "      <td>EI_LMHR_M</td>\n",
       "      <td>dataset</td>\n",
       "      <td>2024-03-01T16:21:00+0100</td>\n",
       "      <td>2024-03-01T16:21:00+0100</td>\n",
       "      <td>1983-01</td>\n",
       "      <td>2024-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2234</th>\n",
       "      <td>Loan and deposit one year interest rate</td>\n",
       "      <td>ENPE_IRT_LD</td>\n",
       "      <td>dataset</td>\n",
       "      <td>2024-01-31T23:00:00+0100</td>\n",
       "      <td>2023-11-28T11:00:00+0100</td>\n",
       "      <td>2005</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5160</th>\n",
       "      <td>Gross domestic product (GDP) at market prices ...</td>\n",
       "      <td>TIPSAU20</td>\n",
       "      <td>dataset</td>\n",
       "      <td>2024-03-05T23:00:00+0100</td>\n",
       "      <td>2024-03-05T23:00:00+0100</td>\n",
       "      <td>1995-Q1</td>\n",
       "      <td>2023-Q4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6499</th>\n",
       "      <td>HICP - inflation rate</td>\n",
       "      <td>TEC00118</td>\n",
       "      <td>dataset</td>\n",
       "      <td>2024-02-22T11:00:00+0100</td>\n",
       "      <td>2024-02-22T11:00:00+0100</td>\n",
       "      <td>2012</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6637</th>\n",
       "      <td>HICP - all items excluding energy and seasonal...</td>\n",
       "      <td>TEICP230</td>\n",
       "      <td>dataset</td>\n",
       "      <td>2024-03-01T11:00:00+0100</td>\n",
       "      <td>2024-03-01T11:00:00+0100</td>\n",
       "      <td>2023-02</td>\n",
       "      <td>2024-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6643</th>\n",
       "      <td>HICP - energy</td>\n",
       "      <td>TEICP250</td>\n",
       "      <td>dataset</td>\n",
       "      <td>2024-03-01T11:00:00+0100</td>\n",
       "      <td>2024-03-01T11:00:00+0100</td>\n",
       "      <td>2023-03</td>\n",
       "      <td>2024-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6647</th>\n",
       "      <td>HICP - food, alcohol and tobacco</td>\n",
       "      <td>TEICP260</td>\n",
       "      <td>dataset</td>\n",
       "      <td>2024-03-01T11:00:00+0100</td>\n",
       "      <td>2024-03-01T11:00:00+0100</td>\n",
       "      <td>2023-03</td>\n",
       "      <td>2024-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title  \\\n",
       "132                       Final consumption expenditure   \n",
       "192                                   Unemployment rate   \n",
       "193                Unemployment rate by education level   \n",
       "214   Gross domestic product (GDP) at current market...   \n",
       "1327                        HICP - monthly data (index)   \n",
       "1330                        HICP - monthly data (index)   \n",
       "1333                        HICP - monthly data (index)   \n",
       "2148               Unemployment rate (%) - monthly data   \n",
       "2234            Loan and deposit one year interest rate   \n",
       "5160  Gross domestic product (GDP) at market prices ...   \n",
       "6499                              HICP - inflation rate   \n",
       "6637  HICP - all items excluding energy and seasonal...   \n",
       "6643                                      HICP - energy   \n",
       "6647                   HICP - food, alcohol and tobacco   \n",
       "\n",
       "                       code     type       last update of data  \\\n",
       "132                 MED_EC2  dataset  2020-05-28T23:00:00+0200   \n",
       "192               MED_PS421  dataset  2020-05-28T23:00:00+0200   \n",
       "193               MED_PS422  dataset  2016-08-29T23:00:00+0200   \n",
       "214            MET_10R_3GDP  dataset  2024-02-28T23:00:00+0100   \n",
       "1327          PRC_HICP_MIDX  dataset  2024-03-01T11:00:00+0100   \n",
       "1330  PRC_HICP_MIDX$DV_1082  dataset  2024-03-01T11:00:00+0100   \n",
       "1333   PRC_HICP_MIDX$DV_651  dataset  2024-03-01T11:00:00+0100   \n",
       "2148              EI_LMHR_M  dataset  2024-03-01T16:21:00+0100   \n",
       "2234            ENPE_IRT_LD  dataset  2024-01-31T23:00:00+0100   \n",
       "5160               TIPSAU20  dataset  2024-03-05T23:00:00+0100   \n",
       "6499               TEC00118  dataset  2024-02-22T11:00:00+0100   \n",
       "6637               TEICP230  dataset  2024-03-01T11:00:00+0100   \n",
       "6643               TEICP250  dataset  2024-03-01T11:00:00+0100   \n",
       "6647               TEICP260  dataset  2024-03-01T11:00:00+0100   \n",
       "\n",
       "     last table structure change data start data end  \n",
       "132     2020-05-28T23:00:00+0200       2005     2018  \n",
       "192     2020-05-28T23:00:00+0200       2005     2019  \n",
       "193     2023-12-21T23:00:00+0100       2000     2015  \n",
       "214     2024-02-28T23:00:00+0100       2000     2022  \n",
       "1327    2024-03-01T11:00:00+0100    1996-01  2024-02  \n",
       "1330    2024-03-01T11:00:00+0100       None     None  \n",
       "1333    2024-03-01T11:00:00+0100       None     None  \n",
       "2148    2024-03-01T16:21:00+0100    1983-01  2024-01  \n",
       "2234    2023-11-28T11:00:00+0100       2005     2022  \n",
       "5160    2024-03-05T23:00:00+0100    1995-Q1  2023-Q4  \n",
       "6499    2024-02-22T11:00:00+0100       2012     2023  \n",
       "6637    2024-03-01T11:00:00+0100    2023-02  2024-01  \n",
       "6643    2024-03-01T11:00:00+0100    2023-03  2024-02  \n",
       "6647    2024-03-01T11:00:00+0100    2023-03  2024-02  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codes[filt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91304b8f-f1e5-4b75-91d6-8b951573830c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# overall inflation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5331d14-541e-4842-ab44-47dd3226c4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = eurostat.get_data('med_ec2') #, filter_pars={'geo': ['DE','FR']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db426671-6f62-437e-a2b4-5f946ff21bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data[1:], columns=data[0]).transpose()\n",
    "df = df.loc[:, (df.loc['unit'] == 'I05') & (df.loc['coicop'] == 'CP00')]\n",
    "df.columns = [f'cpi_{i}' for i in df.loc['geo\\TIME_PERIOD'].values]\n",
    "\n",
    "cpi = df.iloc[5:].copy().dropna().astype(float)\n",
    "cpi.index = [datetime(int(i[:4]), int(i[5:7]), 1) for i in cpi.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57956631-b3e9-473a-b393-0052b9f792c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cpi['pi_de'] = np.log(cpi['cpi_DE']).diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "84996f23-57bf-438d-9dfa-2c175615bf50",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pd_df(cpi, 'cpi.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f7cb87c5-5d80-42a6-9f8c-58a53005abb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# food tobaco inflation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "58cc1198-4f5b-42ba-981c-810a0d71f271",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = eurostat.get_data('TEICP260', filter_pars={'geo': ['DE']})\n",
    "data = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "53a72797-ba65-4cf2-90e8-5b72d222488f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>freq</th>\n",
       "      <th>coicop</th>\n",
       "      <th>unit</th>\n",
       "      <th>geo\\TIME_PERIOD</th>\n",
       "      <th>2023-02</th>\n",
       "      <th>2023-03</th>\n",
       "      <th>2023-04</th>\n",
       "      <th>2023-05</th>\n",
       "      <th>2023-06</th>\n",
       "      <th>2023-07</th>\n",
       "      <th>2023-08</th>\n",
       "      <th>2023-09</th>\n",
       "      <th>2023-10</th>\n",
       "      <th>2023-11</th>\n",
       "      <th>2023-12</th>\n",
       "      <th>2024-01</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>FOOD</td>\n",
       "      <td>I15</td>\n",
       "      <td>DE</td>\n",
       "      <td>139.5</td>\n",
       "      <td>141.3</td>\n",
       "      <td>141.1</td>\n",
       "      <td>141.1</td>\n",
       "      <td>141.2</td>\n",
       "      <td>141.2</td>\n",
       "      <td>141.0</td>\n",
       "      <td>141.5</td>\n",
       "      <td>141.6</td>\n",
       "      <td>142.4</td>\n",
       "      <td>142.4</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>FOOD</td>\n",
       "      <td>PCH_M1</td>\n",
       "      <td>DE</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>FOOD</td>\n",
       "      <td>PCH_M12</td>\n",
       "      <td>DE</td>\n",
       "      <td>18.0</td>\n",
       "      <td>18.6</td>\n",
       "      <td>15.5</td>\n",
       "      <td>13.6</td>\n",
       "      <td>12.6</td>\n",
       "      <td>10.7</td>\n",
       "      <td>9.2</td>\n",
       "      <td>8.1</td>\n",
       "      <td>7.1</td>\n",
       "      <td>6.6</td>\n",
       "      <td>5.8</td>\n",
       "      <td>5.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  freq coicop     unit geo\\TIME_PERIOD 2023-02 2023-03 2023-04 2023-05  \\\n",
       "0    M   FOOD      I15              DE   139.5   141.3   141.1   141.1   \n",
       "1    M   FOOD   PCH_M1              DE     2.0     1.3    -0.1     0.0   \n",
       "2    M   FOOD  PCH_M12              DE    18.0    18.6    15.5    13.6   \n",
       "\n",
       "  2023-06 2023-07 2023-08 2023-09 2023-10 2023-11 2023-12 2024-01  \n",
       "0   141.2   141.2   141.0   141.5   141.6   142.4   142.4    None  \n",
       "1     0.1     0.0    -0.1     0.4     0.1     0.6     0.0     0.9  \n",
       "2    12.6    10.7     9.2     8.1     7.1     6.6     5.8     5.1  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data=data[1:], columns=data[0])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d929bc8f-7406-4d87-85b4-b8b1f9045670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pi prognosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "747a9ca9-8dfd-41f8-b501-30de328b63fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_dt_index(load_pd_df('ecb_prognosis_hicp_dec_2021.csv'), dt_index_col=\"DATE\").iloc[:, 1:]\n",
    "df.index.name = 'date'\n",
    "df.columns = [\"infl_forecast\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53069781-f55d-49a3-8ce5-cda62c4ef9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = load_pd_df('ecb_prognosis_hicp_jun_2021.csv')\n",
    "df1['date'] = df1.DATE.apply(lambda x: datetime(int(x[:4]), 6, 30))\n",
    "df1 = df1.drop('DATE', axis=1).set_index('date').iloc[:, 1:]\n",
    "df1.columns = [\"infl_forecast\"]\n",
    "\n",
    "df = pd.concat([df, df1], axis=0).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "58afe557-0b48-40ec-854a-7b43fd8a19b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pd_df(df, 'infl_prognonsis.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6eeb1f-fc81-4f63-bce2-5b8826b3f61e",
   "metadata": {},
   "source": [
    "# hhp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac1e1c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bophh_suf_202304_v01_wave01.dta\n",
      "bophh_suf_202304_v01_wave02.dta\n",
      "bophh_suf_202304_v01_wave03.dta\n",
      "bophh_suf_202304_v01_wave04.dta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LukasGrahl\\AppData\\Local\\Temp\\ipykernel_21236\\2310966925.py:5: UnicodeWarning: \n",
      "One or more strings in the dta file could not be decoded using utf-8, and\n",
      "so the fallback encoding of latin-1 is being used.  This can happen when a file\n",
      "has been incorrectly encoded by Stata or some other software. You should verify\n",
      "the string values returned are correct.\n",
      "  dta = pd.read_stata(os.path.join(DATA_DIR, 'hhs', file), )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bophh_suf_202304_v01_wave05.dta\n",
      "bophh_suf_202304_v01_wave06.dta\n",
      "bophh_suf_202304_v01_wave07.dta\n",
      "bophh_suf_202304_v01_wave08.dta\n",
      "bophh_suf_202304_v01_wave09.dta\n",
      "bophh_suf_202304_v01_wave10.dta\n",
      "bophh_suf_202304_v01_wave11.dta\n",
      "bophh_suf_202304_v01_wave12.dta\n",
      "bophh_suf_202304_v01_wave13.dta\n",
      "bophh_suf_202304_v01_wave14.dta\n",
      "bophh_suf_202304_v01_wave15.dta\n",
      "bophh_suf_202304_v01_wave16.dta\n",
      "bophh_suf_202304_v01_wave17.dta\n",
      "bophh_suf_202304_v01_wave18.dta\n",
      "bophh_suf_202304_v01_wave19.dta\n",
      "bophh_suf_202304_v01_wave20.dta\n",
      "bophh_suf_202304_v01_wave21.dta\n",
      "bophh_suf_202304_v01_wave22.dta\n",
      "bophh_suf_202304_v01_wave23.dta\n",
      "bophh_suf_202304_v01_wave24.dta\n",
      "bophh_suf_202304_v01_wave25.dta\n",
      "bophh_suf_202304_v01_wave26.dta\n",
      "bophh_suf_202304_v01_wave27.dta\n",
      "'utf-8' codec can't decode byte 0xfc in position 8: invalid start byte\n",
      "bophh_suf_202304_v01_wave28.dta\n",
      "'utf-8' codec can't decode byte 0x80 in position 5: invalid start byte\n",
      "bophh_suf_202304_v01_wave29.dta\n",
      "bophh_suf_202304_v01_wave30.dta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LukasGrahl\\AppData\\Local\\Temp\\ipykernel_21236\\2310966925.py:5: UnicodeWarning: \n",
      "One or more strings in the dta file could not be decoded using utf-8, and\n",
      "so the fallback encoding of latin-1 is being used.  This can happen when a file\n",
      "has been incorrectly encoded by Stata or some other software. You should verify\n",
      "the string values returned are correct.\n",
      "  dta = pd.read_stata(os.path.join(DATA_DIR, 'hhs', file), )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bophh_suf_202304_v01_wave31.dta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LukasGrahl\\AppData\\Local\\Temp\\ipykernel_21236\\2310966925.py:5: UnicodeWarning: \n",
      "One or more strings in the dta file could not be decoded using utf-8, and\n",
      "so the fallback encoding of latin-1 is being used.  This can happen when a file\n",
      "has been incorrectly encoded by Stata or some other software. You should verify\n",
      "the string values returned are correct.\n",
      "  dta = pd.read_stata(os.path.join(DATA_DIR, 'hhs', file), )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bophh_suf_202304_v01_wave32.dta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LukasGrahl\\AppData\\Local\\Temp\\ipykernel_21236\\2310966925.py:5: UnicodeWarning: \n",
      "One or more strings in the dta file could not be decoded using utf-8, and\n",
      "so the fallback encoding of latin-1 is being used.  This can happen when a file\n",
      "has been incorrectly encoded by Stata or some other software. You should verify\n",
      "the string values returned are correct.\n",
      "  dta = pd.read_stata(os.path.join(DATA_DIR, 'hhs', file), )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bophh_suf_202304_v01_wave33.dta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LukasGrahl\\AppData\\Local\\Temp\\ipykernel_21236\\2310966925.py:5: UnicodeWarning: \n",
      "One or more strings in the dta file could not be decoded using utf-8, and\n",
      "so the fallback encoding of latin-1 is being used.  This can happen when a file\n",
      "has been incorrectly encoded by Stata or some other software. You should verify\n",
      "the string values returned are correct.\n",
      "  dta = pd.read_stata(os.path.join(DATA_DIR, 'hhs', file), )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bophh_suf_202304_v01_wave34.dta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LukasGrahl\\AppData\\Local\\Temp\\ipykernel_21236\\2310966925.py:5: UnicodeWarning: \n",
      "One or more strings in the dta file could not be decoded using utf-8, and\n",
      "so the fallback encoding of latin-1 is being used.  This can happen when a file\n",
      "has been incorrectly encoded by Stata or some other software. You should verify\n",
      "the string values returned are correct.\n",
      "  dta = pd.read_stata(os.path.join(DATA_DIR, 'hhs', file), )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bophh_suf_202304_v01_wave35.dta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LukasGrahl\\AppData\\Local\\Temp\\ipykernel_21236\\2310966925.py:5: UnicodeWarning: \n",
      "One or more strings in the dta file could not be decoded using utf-8, and\n",
      "so the fallback encoding of latin-1 is being used.  This can happen when a file\n",
      "has been incorrectly encoded by Stata or some other software. You should verify\n",
      "the string values returned are correct.\n",
      "  dta = pd.read_stata(os.path.join(DATA_DIR, 'hhs', file), )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bophh_suf_202304_v01_wave36.dta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LukasGrahl\\AppData\\Local\\Temp\\ipykernel_21236\\2310966925.py:5: UnicodeWarning: \n",
      "One or more strings in the dta file could not be decoded using utf-8, and\n",
      "so the fallback encoding of latin-1 is being used.  This can happen when a file\n",
      "has been incorrectly encoded by Stata or some other software. You should verify\n",
      "the string values returned are correct.\n",
      "  dta = pd.read_stata(os.path.join(DATA_DIR, 'hhs', file), )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bophh_suf_202304_v01_wave37.dta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LukasGrahl\\AppData\\Local\\Temp\\ipykernel_21236\\2310966925.py:5: UnicodeWarning: \n",
      "One or more strings in the dta file could not be decoded using utf-8, and\n",
      "so the fallback encoding of latin-1 is being used.  This can happen when a file\n",
      "has been incorrectly encoded by Stata or some other software. You should verify\n",
      "the string values returned are correct.\n",
      "  dta = pd.read_stata(os.path.join(DATA_DIR, 'hhs', file), )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bophh_suf_202304_v01_wave38.dta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LukasGrahl\\AppData\\Local\\Temp\\ipykernel_21236\\2310966925.py:5: UnicodeWarning: \n",
      "One or more strings in the dta file could not be decoded using utf-8, and\n",
      "so the fallback encoding of latin-1 is being used.  This can happen when a file\n",
      "has been incorrectly encoded by Stata or some other software. You should verify\n",
      "the string values returned are correct.\n",
      "  dta = pd.read_stata(os.path.join(DATA_DIR, 'hhs', file), )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bophh_suf_202304_v01_wave39.dta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LukasGrahl\\AppData\\Local\\Temp\\ipykernel_21236\\2310966925.py:5: UnicodeWarning: \n",
      "One or more strings in the dta file could not be decoded using utf-8, and\n",
      "so the fallback encoding of latin-1 is being used.  This can happen when a file\n",
      "has been incorrectly encoded by Stata or some other software. You should verify\n",
      "the string values returned are correct.\n",
      "  dta = pd.read_stata(os.path.join(DATA_DIR, 'hhs', file), )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bophh_suf_202304_v01_wave40.dta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LukasGrahl\\AppData\\Local\\Temp\\ipykernel_21236\\2310966925.py:5: UnicodeWarning: \n",
      "One or more strings in the dta file could not be decoded using utf-8, and\n",
      "so the fallback encoding of latin-1 is being used.  This can happen when a file\n",
      "has been incorrectly encoded by Stata or some other software. You should verify\n",
      "the string values returned are correct.\n",
      "  dta = pd.read_stata(os.path.join(DATA_DIR, 'hhs', file), )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bophh_suf_202304_v01_wave41.dta\n",
      "bophh_suf_202304_v01_wave42.dta\n",
      "bophh_suf_202304_v01_wave43.dta\n",
      "bophh_suf_202304_v01_wave44.dta\n",
      "bophh_suf_202304_v01_wave45.dta\n"
     ]
    }
   ],
   "source": [
    "dfs, metadata = [], []\n",
    "for i, file in enumerate(os.listdir(os.path.join(DATA_DIR, 'hhs'))):\n",
    "    print(file)\n",
    "    try:\n",
    "        dta = pd.read_stata(os.path.join(DATA_DIR, 'hhs', file), )\n",
    "        dfs.append(dta)\n",
    "        metadata.append(metadata)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a8de37c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat(dfs, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c9daea8d-41f3-48e0-b166-e9f2edda6d7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LukasGrahl\\AppData\\Local\\Temp\\ipykernel_21236\\422614078.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['date_recorded'] = data[['year', 'month', 'day']].apply(lambda x: datetime(*x.values.astype(int)), axis=1).rename('date_recorded')\n"
     ]
    }
   ],
   "source": [
    "data['date_recorded'] = data[['year', 'month', 'day']].apply(lambda x: datetime(*x.values.astype(int)), axis=1).rename('date_recorded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a1b53dce-1c83-4bc7-859f-bf809879c2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_cols_rename = {'inflexppoint': 'pi_exp', 'inflexppoint_long': 'pi_exp_long', 'expint_sav': 'i_exp', 'devinfpoint': 'pi_perc'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "efbc15ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_cols_parse = {\n",
    "    'id': float,\n",
    "    # 'riskaversion': str,\n",
    "    # 'date_recorded': \n",
    "    'i_exp': float,\n",
    "    'pi_perc': float,\n",
    "    'hhinc': str,\n",
    "    'pinc': str,\n",
    "    'pi_exp': float,\n",
    "    'eduschool': str,\n",
    " 'eduwork': str,\n",
    " 'employ': str,\n",
    " 'profession': str,\n",
    " 'hhsize': str,\n",
    " 'hhchildren': str,\n",
    " 'familystatus': str,\n",
    " 'hhinc': str,\n",
    " 'pinc': str,\n",
    "    'homeown': str,\n",
    "    'pi_exp_long': float,\n",
    "}\n",
    "dict_cols_parse.update({f'infexprob_{i}': str for i in list(map(chr, range(97, 107)))})\n",
    "dict_cols_parse.update({f'incexp_{i}': str for i in list(map(chr, range(97, 107)))})\n",
    "dict_cols_parse.update({f'mainshopper_{i}': str for i in list(map(chr, range(97, 101)))})\n",
    "dict_cols_parse.update({f'netwealth_detail_{i}': str for i in list(map(chr, range(97, 104)))})\n",
    "# dict_cols_parse.update({f'mainshopper_{i}': str for i in list(map(chr, range(97, 1007)))})\n",
    "\n",
    "lst_cols = list(dict_cols_parse.keys())\n",
    "lst_cols.extend(['date_recorded'])\n",
    "\n",
    "_ = [\n",
    "        \"don't know\",\n",
    "        'no answer',\n",
    "        'does not apply',\n",
    "        'nan',\n",
    "    ]\n",
    "dict_parse_nan = dict(zip(_, list([np.nan]) * len(_)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4ab2f998-473d-45f8-9fb7-9f1987eda3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_inc_replace = {'3.500 to 3.999 EUR': '3.500 to 3.999 EUR',\n",
    " '2.000 to 2.499 EUR': '2.000 to 2.499 EUR',\n",
    " '500 to 999 EUR': '500 to 999 EUR',\n",
    " '3000 - < 3500 EUR': '3.000 to 3.499 EUR',\n",
    " '3500 - < 4000 EUR': '3.500 to 3.999 EUR',\n",
    " 'under 500 EUR': 'under 500 EUR',\n",
    " '> 4499 EUR': '5.000 to 5.999 EUR',\n",
    " '1000 - < 1500 EUR': '1.000 to 1.499 EUR',\n",
    " '2000 - < 2500 EUR': '2.000 to 2.499 EUR',\n",
    " np.nan: np.nan,\n",
    " '< 500 EUR': 'under 500 EUR',\n",
    " '3.000 to 3.499 EUR': '3.000 to 3.499 EUR',\n",
    " '6.000 to 7.999 EUR': '6.000 to 7.999 EUR',\n",
    " '4000 - < 4500 EUR': '4.000 to 4.999 EUR',\n",
    " '4.000 to 4.999 EUR': '4.000 to 4.999 EUR',\n",
    " '5.000 to 5.999 EUR': '5.000 to 5.999 EUR',\n",
    " '10.000 EUR and more': '10.000 EUR and more',\n",
    " '6.000 EUR and more': '6.000 to 7.999 EUR',\n",
    " '2500 - < 3000 EUR': '2.500 to 2.999 EUR',\n",
    " '8.000 to 9.999 EUR': '8.000 to 9.999 EUR',\n",
    " '1500 - < 2000 EUR': '1.500 to 1.999 EUR',\n",
    " '1.500 to 1.999 EUR': '1.500 to 1.999 EUR',\n",
    " '500 - < 1000 EUR': '500 to 999 EUR',\n",
    "  '500 bis 999 EUR': '500 to 999 EUR',\n",
    " '2.500 to 2.999 EUR': '2.500 to 2.999 EUR',\n",
    " '1.000 to 1.499 EUR': '1.000 to 1.499 EUR'}\n",
    "dict_inc_replace.update(dict_parse_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "186c7832-e141-4e33-949e-327598f952aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.rename(columns=dict_cols_rename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "7a94f8d2-def4-44d1-b137-96023211cdf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "39f3d0bd-bb39-4469-b999-7300afe7c4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data[lst_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5a94d5b4-8ea4-4455-abd7-8da2c3a96549",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a5d9d204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# del data, dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a4d03aec-955b-4482-96a5-0da61f28c62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date_forecast'] = df.date_recorded + timedelta(days=365)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "7c1cb7bb-474c-4b0c-a5f9-14aab073d878",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['hhinc'] = df.hhinc.map(dict_inc_replace)\n",
    "df['pinc'] = df['pinc'].map(dict_inc_replace)\n",
    "for col in ['pi_exp', 'pi_perc', 'i_exp', 'pi_exp_long',]:\n",
    "    df = df.drop(col, axis=1).join(df[col].apply(lambda x: dict_parse_nan[x] if x in dict_parse_nan.keys() else x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c9268fc7-fed5-4985-a203-10df0595d495",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LukasGrahl\\AppData\\Local\\Temp\\ipykernel_21236\\3703843038.py:3: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[col] = df[col].replace(dict_parse_nan)\n"
     ]
    }
   ],
   "source": [
    "cols = [i for i in dict_cols_parse if sum([term in i for term in ['infexprob', 'incexp']]) > 0]\n",
    "for col in cols:\n",
    "    df[col] = df[col].replace(dict_parse_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a0f6a3fc-99a7-4dde-aefa-dae16e62a6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# midpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "3897c86c-fd69-4081-b29f-500e6ec4e55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_hhinc_midpoint = {'1.000 to 1.499 EUR': 1250,\n",
    " '1.500 to 1.999 EUR': 1750,\n",
    " '10.000 EUR and more': 15000,\n",
    " '2.000 to 2.499 EUR': 2250,\n",
    " '2.500 to 2.999 EUR': 2750,\n",
    " '3.000 to 3.499 EUR': 3250,\n",
    " '3.500 to 3.999 EUR': 3750,\n",
    " '4.000 to 4.999 EUR': 4500,\n",
    " '5.000 to 5.999 EUR': 5500,\n",
    " '500 to 999 EUR': 750,\n",
    " '6.000 to 7.999 EUR': 7000,\n",
    " '8.000 to 9.999 EUR': 9000,\n",
    " None: np.nan,\n",
    " 'under 500 EUR': 250}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3d440617-23c0-4062-bcae-649ac8fe6e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['pinc_midpoint'] = df['pinc'].map(dict_hhinc_midpoint)\n",
    "df = df.sort_values('date_recorded')\n",
    "sub = df.set_index(['id', 'date_recorded',])['pinc_midpoint'].unstack()\n",
    "sub = sub.ffill(axis=1).diff(axis=1).stack().rename('pinc_delta')\n",
    "df = df.set_index(['id', 'date_recorded']).join(sub).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b1378947-dd12-4414-96e9-eb517dbfdd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['hhinc_midpoint'] = df['hhinc'].map(dict_hhinc_midpoint)\n",
    "df = df.sort_values('date_recorded')\n",
    "sub = df.set_index(['id', 'date_recorded',])['hhinc_midpoint'].unstack()\n",
    "sub = sub.ffill(axis=1).diff(axis=1).stack().rename('hhinc_delta')\n",
    "df = df.set_index(['id', 'date_recorded']).join(sub).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "4ee11b27-7768-438b-a424-9f8586e34db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_educ_work = {\n",
    "    ' Completed vocational training (vocational school or commercial college)': 'vocational',\n",
    " ' Currently in training or studying (bachelor’s degree not yet completed)': 'student',\n",
    " 'Another professional qualification': 'vocational',\n",
    " 'Bachelor’s degree, applied sciences degree, completed training at an engineering college': 'bachelor',\n",
    " 'Completed training at a technical or commercial college, school for master craftsmen or engineers or university of co-operative education with shorter preparation time (up to 880 hours)': 'meister',\n",
    " 'Completed training at a university of cooperative education with longer preparation time (more than 880 hours)': 'bachelor',\n",
    " 'Completed vocational training (apprenticeship)': 'vocational',\n",
    " 'Diploma or master’s degree, completed teacher training course': 'masters',\n",
    " 'Doctorate / postdoctoral qualification obtained': 'phd',\n",
    " 'No vocational training or university degree  completed': 'high school',\n",
    " 'apprenticeship': 'vocational',\n",
    " 'doctorate': 'phd',\n",
    " 'in training/studying': 'student',\n",
    " 'master/diploma': 'masters',\n",
    " 'no degree': 'high school',\n",
    " 'technical or commercial college': 'bachelor',\n",
    " 'university of cooperative education': 'bachelor',\n",
    " 'vocational school': 'vocational',\n",
    "}\n",
    "dict_educ_work.update(dict_parse_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "8e5fe711-d385-41a7-b065-65e4bfc02e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['eduwork_slim'] = df['eduwork'].apply(lambda x: dict_educ_work[x] if x in dict_educ_work.keys() else x).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "1feafcad-7243-420e-b7f9-a85fae7a95d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_employ = {'Apprenticeship': 'in educ',\n",
    " 'Low-paid part-time (Mini-Job)': 'Infrequent employment',\n",
    " 'Military service / BuFDi / FSJ': 'in educ',\n",
    " 'One-euro job': 'Low-paid part-time (Mini-Job)',\n",
    " 'Partial retirement scheme': 'Infrequent employment',\n",
    " 'Retraining': 'voluntary year',\n",
    " 'casual or irregular employment': 'Infrequent employment',\n",
    " 'early retirement': 'retirement',\n",
    " 'full-time employment': 'Employed, full-time',\n",
    " 'other non-employment': 'Unemployed',\n",
    " 'parental leave': 'voluntary year',\n",
    " 'part-time employment': 'Employed, part-time',\n",
    " 'student/internship': 'in educ',\n",
    " 'unemployed': 'Unemployed',\n",
    "              }\n",
    "dict_employ.update(dict_parse_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d8b68040-b3b2-45a4-aaab-d1d8802abfbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['employ_slim'] = df['employ'].apply(lambda x: dict_employ[x] if x in dict_employ.keys() else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "68746181-abdf-4ec0-b39d-a373f34f4821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse nan\n",
    "for col in ['profession', 'hhsize', *[i for i in df.columns if 'mainshopper' in i], *[i for i in df.columns if 'netwealth' in i]]:\n",
    "    df[col] = df[col].apply(lambda x: dict_parse_nan[x.lower()] if x in dict_parse_nan.keys() else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "989261f4-53bb-4162-879a-18cfed1f0ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a-d cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "408af2c0-21a8-4505-b77c-5dbceb392172",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['is_food_shop'] = ~(df['mainshopper_a'] == 'rather my partner')\n",
    "df['is_invest_shop'] = ~(df['mainshopper_b'] == 'rather my partner')\n",
    "df['is_invest_manag'] = ~(df['mainshopper_d'] == 'rather my partner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "4864ac24-3ae3-419e-baaa-7942b87a1793",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_networth_mid_point = {'1 to 2.500 EUR': 1250,\n",
    " '10.000 to 25.000 EUR': 17500,\n",
    " '100.000 to 250.000 EUR': 175000,\n",
    " '2.500 to 5.000 EUR': 3250,\n",
    " '25.000 to 50.000 EUR': 37500,\n",
    " '250.000 to 500.000 EUR': 750000,\n",
    " '5.000 to 10.000 EUR': 7500,\n",
    " '50.000 to 100.000 EUR': 75000,\n",
    " '500.000 EUR or more': 500_000,\n",
    " 'no bank deposits': np.nan}\n",
    "dict_debt_midpoint = {\n",
    "    '0 (no debt)': 0,\n",
    " '1 to 1.000 EUR': 500,\n",
    " '1.000 to 2.000 EUR': 1500,\n",
    " '10.000 to 20.000 EUR': 15_000,\n",
    " '100.000 EUR or more': 100_000,\n",
    " '2.000 to 5.000 EUR': 3_250,\n",
    " '20.000 to 40.000 EUR': 30_000,\n",
    " '40.000 to 60.000 EUR': 50_000,\n",
    " '5.000 to 10.000 EUR': 7_500,\n",
    " '60.000 to 100.000 EUR': 80_000,\n",
    " 'no debt': 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "6fef1fb9-9952-451e-a8a7-6f9bb1bb3297",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['wealth_bank'] = df['netwealth_detail_a'].map(dict_networth_mid_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "009c08d2-43ae-4fa0-a591-4cf0989cac4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['debt'] = df['netwealth_detail_g'].map(dict_debt_midpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "d5f8c749-ba7f-4436-aef5-7235d8df9254",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['is_homown'] = df['homeown'].apply(lambda x: x in ['live in own apartment',\n",
    "                                                     'live in own house',\n",
    "                                                     'own flat',\n",
    "                                                     'own house',\n",
    "                                                     'rent but own other home(s)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "d978458b-bcbd-4b19-a3c4-f29428412581",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.astype({k: v for k, v in dict_cols_parse.items() if k in df.columns})\n",
    "df = df.replace({'nan': np.nan})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "43d19764-4a39-4927-ac9b-c3463058807c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_feather(os.path.join(DATA_DIR, 'hhp.feather'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ee3c04-1c77-4a1a-b9d6-7355ba0f9b7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b88309-191c-4f1b-9a18-faf939d3bd59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mamba_env_memoire2",
   "language": "python",
   "name": "mamba_env_memoire2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
